
# üìù Informe de Detecci√≥n y Segmentaci√≥n de Objetos con YOLOv8 y SAM en Google Colab

## üìå Objetivo

El objetivo de este trabajo es implementar un pipeline de visi√≥n por computador en Google Colab que permita:

- Cargar una imagen desde Google Drive.
- Detectar objetos en la imagen utilizando el modelo YOLOv8.
- Segmentar los objetos detectados usando Segment Anything Model (SAM).
- Visualizar los resultados (cajas y m√°scaras).
- Guardar las detecciones en un archivo CSV con el nombre de la clase y las coordenadas de la caja delimitadora.

---

## üìÇ 1. Carga de Imagen desde Google Drive

Se utiliz√≥ la API de Google Colab para montar Google Drive y acceder a una imagen ubicada en la carpeta del usuario. La imagen fue visualizada utilizando la biblioteca `PIL` y `matplotlib`.

```python
from google.colab import drive
drive.mount('/content/drive')
...
img = Image.open(image_path)
plt.imshow(img)
```

> ‚úÖ Resultado: la imagen fue cargada correctamente desde Drive y se mostr√≥ en el cuaderno.

---

## üéØ 2. Detecci√≥n de Objetos con YOLOv8

Se utiliz√≥ el modelo YOLOv8 (`yolov8n.pt`) de la librer√≠a `ultralytics` para detectar objetos en la imagen cargada.

```python
model = YOLO('yolov8n.pt')
results = model(img)
```

Posteriormente, se imprimieron las clases detectadas junto a sus coordenadas de caja delimitadora (`xmin`, `ymin`, `xmax`, `ymax`).

> ‚úÖ Resultado: se identificaron y mostraron m√∫ltiples objetos con sus respectivas clases y coordenadas.

---

## üñºÔ∏è 3. Visualizaci√≥n de Resultados de Detecci√≥n

Se visualizaron las cajas delimitadoras sobre la imagen utilizando:

```python
results[0].plot()
plt.imshow(results[0].plot())
```

> üñºÔ∏è Resultado: imagen con las detecciones superpuestas, lista para an√°lisis visual.

---

## ‚úÇÔ∏è 4. Segmentaci√≥n con Segment Anything Model (SAM)

Se emple√≥ `SAM` (modelo `sam_b.pt`) para refinar las detecciones de YOLO usando segmentaci√≥n basada en las cajas predichas.

```python
sam = SAM('sam_b.pt')
sam_results = sam(img, bboxes=[coords])
```

Cada m√°scara generada fue visualizada superpuesta a la imagen original:

```python
plt.imshow(img)
plt.imshow(mask, cmap='viridis', alpha=0.5)
```

> ‚úÖ Resultado: se generaron m√°scaras segmentadas que permiten una mejor comprensi√≥n de la forma de cada objeto.

---

## üìÑ 5. Exportaci√≥n de Resultados a CSV

Se guardaron los resultados de detecci√≥n en un archivo `.csv` con el siguiente formato:

| Class Name | xmin | ymin | xmax | ymax |
|------------|------|------|------|------|

El c√≥digo correspondiente fue:

```python
with open(csv_file_path, mode='w', newline='') as file:
    ...
    writer.writerow([class_name, coords[0], coords[1], coords[2], coords[3]])
```

> ‚úÖ Resultado: se gener√≥ correctamente el archivo `detections.csv` en Google Drive.

---

## üß† Conclusiones

- Se demostr√≥ una integraci√≥n exitosa de m√∫ltiples modelos de visi√≥n por computador: YOLOv8 para detecci√≥n y SAM para segmentaci√≥n.
- El flujo completo (desde carga de datos hasta exportaci√≥n de resultados) fue implementado eficientemente en Colab.
- Este pipeline puede ser f√°cilmente escalado para conjuntos de im√°genes o usado como base para tareas m√°s complejas como reconocimiento sem√°ntico o tracking.

